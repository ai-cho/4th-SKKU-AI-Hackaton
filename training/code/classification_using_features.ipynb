{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# 모델 경로 체크\n","# test example 경로 체크"],"metadata":{"id":"jx5tXktJFh_C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## AI Hub에서 제안된 모델 사용 (EfficientNet)"],"metadata":{"id":"wU0WE0TRQn7r"}},{"cell_type":"code","source":["import tensorflow as tf\n","from keras.utils import Sequence\n","import math\n","import numpy as np\n","import json\n","import cv2 as cv\n","import random\n","from datetime import datetime\n","import keras.applications as ka"],"metadata":{"id":"1uWNfNnE9kQ1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IM_HEIGHT = 224\n","IM_WIDTH = 224\n","\n","\n","def preprocess_image(np_image, net_type='efficientnet'):\n","    assert net_type in ['mobilenet', 'resnet50', 'efficientnet'], 'network not in the list'\n","\n","    m_image = tf.convert_to_tensor(np_image, dtype=tf.float32)\n","\n","    if net_type == 'efficientnet':\n","        return m_image\n","\n","def read_data_1_input(json_file):\n","\n","    temp, hum, co2 = get_data(json_file)\n","\n","    temp = div_func(temp)\n","    temp = normalize_resize_concat(temp, resize=True)\n","\n","    hum = div_func(hum)\n","    hum = normalize_resize_concat(hum, resize=True)\n","\n","    co2 = div_func(co2)\n","    co2 = normalize_resize_concat(co2, resize=True)\n","\n","    return cv.merge((temp, hum, co2))\n","\n","\n","def get_data(annot_file):\n","    with open(annot_file, \"r\", encoding='UTF-8-SIG') as f:\n","        data = json.loads(f.read())\n","\n","    temp = np.array(data[\"environment\"]['in_temperature'], dtype='float')\n","    humidity = np.array(data[\"environment\"]['in_humidity'], dtype='float')\n","    co2 = np.array(data[\"environment\"]['in_carbon_monoxide'], dtype='float')\n","\n","    return temp, humidity, co2\n","\n","\n","def div_func(x):\n","    x = x.squeeze()\n","    x1 = x[:189]\n","    for n in range(1, 189):\n","        x1 = np.vstack((x1, x[n*189:(n+1)*189]))\n","    return x1\n","\n","def normalize_resize_concat(x, hist=False, resize=False, merge=False):\n","\n","    x = cv.normalize(x, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n","    x = np.array(x, np.uint8)\n","\n","    if resize:\n","        x = cv.resize(x, (IM_HEIGHT, IM_WIDTH), cv.INTER_AREA)\n","\n","    if hist:\n","        x = cv.equalizeHist(x)\n","\n","    if merge:\n","        x = cv.merge((x, x, x))\n","\n","    return x"],"metadata":{"id":"KjGhEQHb9Dhd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def make_model_efficientnet_1input():\n","    m1 = tf.keras.applications.EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n","    gap1 = tf.keras.layers.GlobalAveragePooling2D()(m1.output)\n","    l3 = tf.keras.layers.Dense(7, activation='softmax')(gap1)\n","    model = tf.keras.models.Model(inputs=m1.inputs, outputs=l3)\n","    return model"],"metadata":{"id":"x-WWS4pJ93T-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlfJy6gX6kVf"},"outputs":[],"source":["def get_prediction(model_file, raw_data):\n","    data = read_data_1_input(raw_data)\n","    data = preprocess_image(np_image=data, net_type='efficientnet')\n","    prediction = model_file.predict(np.expand_dims(data, axis=0), batch_size=1)\n","    return np.argmax(prediction)\n","\n","\n","# pretrained model 사용\n","model = make_model_efficientnet_1input()\n","# net_name = '/content/network.hdf5'\n","net_name = 'input model path'\n","model.load_weights(net_name)"]},{"cell_type":"code","source":["# Example of data\n","# json_file = '/content/drive/MyDrive/제4회 AI교육 해커톤/Sample/time_series_data/성충/성충_응애/007/B_001_001_20230822083841_001_002_001_001.json'\n","json_file = 'input json file path'\n","\n","m_prediction = get_prediction(model, json_file)\n","\n","class_names = [\"유충_정상\", \"유충_응애\", \"유충_석고병\", \"유충_부저병\", \"성충_정상\", \"성충_응애\", \"성충_날개불구바이러스감염증\"]\n","print(f'Prediction is class {m_prediction}, => {class_names[m_prediction]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ys4lPfulAVKE","executionInfo":{"status":"ok","timestamp":1728657385033,"user_tz":-540,"elapsed":672,"user":{"displayName":"조정환","userId":"13053940354475988326"}},"outputId":"b4c418ab-2c0b-4ad3-c69c-2705068d5962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 115ms/step\n","Prediction is class 5, => 성충_응애\n"]}]},{"cell_type":"code","source":["!pip install torch --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2rT5ElGl28eh","executionInfo":{"status":"ok","timestamp":1728688414087,"user_tz":-540,"elapsed":3665,"user":{"displayName":"조정환","userId":"13053940354475988326"}},"outputId":"c3ab1754-57b2-4170-a977-2ddd559f6543"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"markdown","source":["## 시계열 특성 이용하여 LSTM training (from scratch)"],"metadata":{"id":"l6jtqRWJQu24"}},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","import torch\n","\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# LSTM 모델 정의\n","class LSTMModel(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(LSTMModel, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        h0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n","        c0 = torch.zeros(num_layers, x.size(0), hidden_size).to(device)\n","        out, _ = self.lstm(x, (h0, c0))\n","        out = self.fc(out[:, -1, :])\n","        return out\n","\n","# 데이터셋 클래스 정의\n","class BeeDataset(Dataset):\n","    def __init__(self, data_dir, target_classes, seq_length):\n","        self.data = []\n","        self.labels = []\n","        self.seq_length = seq_length\n","        self.scaler = MinMaxScaler()\n","\n","        for target_class in target_classes:\n","            class_dir = os.path.join(data_dir, target_class)\n","\n","            for folder in os.listdir(class_dir):\n","                folder_path = os.path.join(class_dir, folder)\n","                if os.path.isdir(folder_path):\n","                    # 폴더 내에서 .json 파일을 찾기\n","                    for file in os.listdir(folder_path):\n","                        if file.endswith(\".json\"):\n","                            json_file = os.path.join(folder_path, file)\n","                            with open(json_file, 'r', encoding='utf-8') as f:\n","                                json_data = json.load(f)\n","                                # 시계열 데이터 불러오기 (단 최근 100개만 사용)\n","                                in_temp = json_data['environment']['in_temperature'][-100:]\n","                                hum = json_data['environment']['in_humidity'][-100:]\n","                                co = json_data['environment']['in_carbon_monoxide'][-100:]\n","\n","                                # feature로 사용할 데이터를 결합\n","                                features = np.array([in_temp, hum, co]).T\n","                                # 정규화\n","                                features = self.scaler.fit_transform(features)\n","\n","                                # 시퀀스 길이에 맞게 슬라이딩 윈도우 방식으로 분할\n","                                for i in range(len(features) - seq_length):\n","                                    self.data.append(features[i:i + seq_length])\n","                                    self.labels.append(target_classes.index(target_class))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.data[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n","\n","# 학습 파라미터 설정\n","input_size = 3  # in_temperature, in_humidity, in_carbon_monoxide\n","hidden_size = 64\n","num_layers = 2\n","output_size = 7  # 각 클래스의 수\n","seq_length = 10\n","batch_size = 32\n","learning_rate = 0.001\n","num_epochs = 100\n","\n","# 데이터 로드\n","data_dir = '/content/drive/MyDrive/제4회 AI교육 해커톤/Sample/time_series_data/data'  # 데이터 폴더 경로\n","target_classes = ['유충_정상', '유충_응애', '유충_석고병', '유충_부저병', '성충_정상', '성충_응애', '성충_날개불구바이러스감염증']\n","\n","dataset = BeeDataset(data_dir, target_classes, seq_length)\n","data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"],"metadata":{"id":"03QgUgQ90ECk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, random_split\n","\n","def train_val_split(dataset, train_ratio=0.5):\n","    train_size = int(train_ratio * len(dataset))\n","    val_size = len(dataset) - train_size\n","    return random_split(dataset, [train_size, val_size])\n","\n","# Train/Validation Split\n","train_dataset, val_dataset = train_val_split(dataset, train_ratio=0.5)\n","\n","# DataLoader 설정\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"],"metadata":{"id":"FbY8TUr_5o8W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20, device='cuda'):\n","    model = model.to(device)  # 모델을 지정된 장치로 이동\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        correct_train = 0\n","        total_train = 0\n","        cnt = 0\n","        for features, labels in train_loader:\n","            features = features.to(device)  # 입력 데이터를 지정된 장치로 이동\n","            labels = labels.to(device)      # 라벨을 지정된 장치로 이동\n","\n","            optimizer.zero_grad()\n","            outputs = model(features)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            _, predicted = torch.max(outputs, 1)\n","            total_train += labels.size(0)\n","            correct_train += (predicted == labels).sum().item()\n","\n","        train_accuracy = 100 * correct_train / total_train\n","        print(1)\n","        # Validation\n","        model.eval()\n","        val_loss = 0.0\n","        correct_val = 0\n","        total_val = 0\n","\n","        with torch.no_grad():\n","            for features, labels in val_loader:\n","                features = features.to(device)  # 입력 데이터를 지정된 장치로 이동\n","                labels = labels.to(device)      # 라벨을 지정된 장치로 이동\n","\n","                outputs = model(features)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item()\n","\n","                _, predicted = torch.max(outputs, 1)\n","                total_val += labels.size(0)\n","                correct_val += (predicted == labels).sum().item()\n","\n","        val_accuracy = 100 * correct_val / total_val\n","\n","        print(f'Epoch [{epoch+1}/{num_epochs}], '\n","              f'Train Loss: {train_loss/len(train_loader):.4f}, '\n","              f'Train Accuracy: {train_accuracy:.2f}%, '\n","              f'Val Loss: {val_loss/len(val_loader):.4f}, '\n","              f'Val Accuracy: {val_accuracy:.2f}%')\n"],"metadata":{"id":"BDLA3D5U5wvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_size = 3  # in_temperature, in_humidity, in_carbon_monoxide\n","hidden_size = 64\n","num_layers = 2\n","output_size = 7  # 각 클래스의 수\n","seq_length = 10\n","batch_size = 32\n","learning_rate = 0.001\n","num_epochs = 100"],"metadata":{"id":"2IWoYrNYRcgj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vvl_S5xK5ys_","executionInfo":{"status":"error","timestamp":1728690302277,"user_tz":-540,"elapsed":155192,"user":{"displayName":"조정환","userId":"13053940354475988326"}},"outputId":"57c08334-998f-406a-f044-87dce4b438e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","Epoch [1/100], Train Loss: 1.6712, Train Accuracy: 31.02%, Val Loss: 1.5438, Val Accuracy: 37.35%\n","1\n","Epoch [2/100], Train Loss: 1.4503, Train Accuracy: 40.46%, Val Loss: 1.4146, Val Accuracy: 43.29%\n","1\n","Epoch [3/100], Train Loss: 1.3779, Train Accuracy: 43.65%, Val Loss: 1.3664, Val Accuracy: 43.84%\n","1\n","Epoch [4/100], Train Loss: 1.3346, Train Accuracy: 45.47%, Val Loss: 1.3119, Val Accuracy: 47.39%\n","1\n","Epoch [5/100], Train Loss: 1.2999, Train Accuracy: 47.50%, Val Loss: 1.3276, Val Accuracy: 46.71%\n","1\n","Epoch [6/100], Train Loss: 1.2738, Train Accuracy: 48.65%, Val Loss: 1.2456, Val Accuracy: 50.03%\n","1\n","Epoch [7/100], Train Loss: 1.2406, Train Accuracy: 50.09%, Val Loss: 1.2844, Val Accuracy: 47.67%\n","1\n","Epoch [8/100], Train Loss: 1.2179, Train Accuracy: 50.76%, Val Loss: 1.2809, Val Accuracy: 46.17%\n","1\n","Epoch [9/100], Train Loss: 1.1850, Train Accuracy: 52.24%, Val Loss: 1.1948, Val Accuracy: 51.39%\n","1\n","Epoch [10/100], Train Loss: 1.1587, Train Accuracy: 53.33%, Val Loss: 1.1609, Val Accuracy: 53.18%\n","1\n","Epoch [11/100], Train Loss: 1.1197, Train Accuracy: 55.05%, Val Loss: 1.1306, Val Accuracy: 54.95%\n","1\n","Epoch [12/100], Train Loss: 1.0814, Train Accuracy: 56.35%, Val Loss: 1.0893, Val Accuracy: 55.97%\n","1\n","Epoch [13/100], Train Loss: 1.0723, Train Accuracy: 56.94%, Val Loss: 1.1226, Val Accuracy: 55.62%\n","1\n","Epoch [14/100], Train Loss: 1.0234, Train Accuracy: 59.43%, Val Loss: 1.0359, Val Accuracy: 58.84%\n","1\n","Epoch [15/100], Train Loss: 0.9829, Train Accuracy: 61.31%, Val Loss: 1.0004, Val Accuracy: 60.86%\n","1\n","Epoch [16/100], Train Loss: 0.9580, Train Accuracy: 62.63%, Val Loss: 1.0082, Val Accuracy: 60.81%\n","1\n","Epoch [17/100], Train Loss: 0.9222, Train Accuracy: 63.98%, Val Loss: 0.9406, Val Accuracy: 64.32%\n","1\n","Epoch [18/100], Train Loss: 0.8801, Train Accuracy: 66.00%, Val Loss: 0.9894, Val Accuracy: 61.97%\n","1\n","Epoch [19/100], Train Loss: 0.8497, Train Accuracy: 67.15%, Val Loss: 0.8789, Val Accuracy: 66.65%\n","1\n","Epoch [20/100], Train Loss: 0.8191, Train Accuracy: 68.67%, Val Loss: 0.8673, Val Accuracy: 66.67%\n","1\n","Epoch [21/100], Train Loss: 0.7884, Train Accuracy: 69.97%, Val Loss: 0.8486, Val Accuracy: 67.60%\n","1\n","Epoch [22/100], Train Loss: 0.7630, Train Accuracy: 71.23%, Val Loss: 0.8029, Val Accuracy: 69.75%\n","1\n","Epoch [23/100], Train Loss: 0.7306, Train Accuracy: 72.35%, Val Loss: 0.8411, Val Accuracy: 68.22%\n","1\n","Epoch [24/100], Train Loss: 0.7013, Train Accuracy: 73.83%, Val Loss: 0.7721, Val Accuracy: 71.44%\n","1\n","Epoch [25/100], Train Loss: 0.6778, Train Accuracy: 74.81%, Val Loss: 0.7583, Val Accuracy: 71.67%\n","1\n","Epoch [26/100], Train Loss: 0.6503, Train Accuracy: 76.13%, Val Loss: 0.7137, Val Accuracy: 74.13%\n","1\n","Epoch [27/100], Train Loss: 0.6178, Train Accuracy: 77.32%, Val Loss: 0.7421, Val Accuracy: 73.19%\n","1\n","Epoch [28/100], Train Loss: 0.6122, Train Accuracy: 77.53%, Val Loss: 0.7393, Val Accuracy: 72.91%\n","1\n","Epoch [29/100], Train Loss: 0.5857, Train Accuracy: 78.82%, Val Loss: 0.7748, Val Accuracy: 71.74%\n","1\n","Epoch [30/100], Train Loss: 0.5676, Train Accuracy: 79.52%, Val Loss: 0.6741, Val Accuracy: 76.56%\n","1\n","Epoch [31/100], Train Loss: 0.5406, Train Accuracy: 80.50%, Val Loss: 0.6794, Val Accuracy: 76.53%\n","1\n","Epoch [32/100], Train Loss: 0.5302, Train Accuracy: 80.57%, Val Loss: 0.6408, Val Accuracy: 77.80%\n","1\n","Epoch [33/100], Train Loss: 0.5107, Train Accuracy: 81.05%, Val Loss: 0.6143, Val Accuracy: 78.34%\n","1\n","Epoch [34/100], Train Loss: 0.4831, Train Accuracy: 82.48%, Val Loss: 0.6184, Val Accuracy: 78.08%\n","1\n","Epoch [35/100], Train Loss: 0.4610, Train Accuracy: 83.53%, Val Loss: 0.5858, Val Accuracy: 79.45%\n","1\n","Epoch [36/100], Train Loss: 0.4541, Train Accuracy: 83.64%, Val Loss: 0.5709, Val Accuracy: 80.76%\n","1\n","Epoch [37/100], Train Loss: 0.4398, Train Accuracy: 84.32%, Val Loss: 0.5931, Val Accuracy: 79.38%\n","1\n","Epoch [38/100], Train Loss: 0.4437, Train Accuracy: 83.99%, Val Loss: 0.5882, Val Accuracy: 79.68%\n","1\n","Epoch [39/100], Train Loss: 0.4139, Train Accuracy: 85.03%, Val Loss: 0.5422, Val Accuracy: 81.85%\n","1\n","Epoch [40/100], Train Loss: 0.4061, Train Accuracy: 85.46%, Val Loss: 0.7070, Val Accuracy: 76.13%\n","1\n","Epoch [41/100], Train Loss: 0.4002, Train Accuracy: 85.50%, Val Loss: 0.5355, Val Accuracy: 82.13%\n","1\n","Epoch [42/100], Train Loss: 0.4033, Train Accuracy: 85.40%, Val Loss: 0.5339, Val Accuracy: 82.09%\n","1\n","Epoch [43/100], Train Loss: 0.3540, Train Accuracy: 87.29%, Val Loss: 0.5579, Val Accuracy: 81.74%\n","1\n","Epoch [44/100], Train Loss: 0.3572, Train Accuracy: 87.02%, Val Loss: 0.5146, Val Accuracy: 83.12%\n","1\n","Epoch [45/100], Train Loss: 0.3563, Train Accuracy: 86.98%, Val Loss: 0.5976, Val Accuracy: 80.07%\n","1\n","Epoch [46/100], Train Loss: 0.3414, Train Accuracy: 87.50%, Val Loss: 0.5287, Val Accuracy: 82.81%\n","1\n","Epoch [47/100], Train Loss: 0.3387, Train Accuracy: 87.70%, Val Loss: 0.5303, Val Accuracy: 81.54%\n","1\n","Epoch [48/100], Train Loss: 0.3249, Train Accuracy: 88.29%, Val Loss: 0.4861, Val Accuracy: 83.93%\n","1\n","Epoch [49/100], Train Loss: 0.3317, Train Accuracy: 87.85%, Val Loss: 0.5697, Val Accuracy: 81.19%\n","1\n","Epoch [50/100], Train Loss: 0.3088, Train Accuracy: 88.63%, Val Loss: 0.4920, Val Accuracy: 83.72%\n","1\n","Epoch [51/100], Train Loss: 0.2885, Train Accuracy: 89.45%, Val Loss: 0.4840, Val Accuracy: 84.30%\n","1\n","Epoch [52/100], Train Loss: 0.2955, Train Accuracy: 89.13%, Val Loss: 0.5082, Val Accuracy: 83.37%\n","1\n","Epoch [53/100], Train Loss: 0.3013, Train Accuracy: 89.33%, Val Loss: 0.4713, Val Accuracy: 84.17%\n","1\n","Epoch [54/100], Train Loss: 0.2807, Train Accuracy: 89.74%, Val Loss: 0.4727, Val Accuracy: 84.22%\n","1\n","Epoch [55/100], Train Loss: 0.2848, Train Accuracy: 89.56%, Val Loss: 0.4739, Val Accuracy: 84.35%\n","1\n","Epoch [56/100], Train Loss: 0.2744, Train Accuracy: 89.85%, Val Loss: 0.4703, Val Accuracy: 84.74%\n","1\n","Epoch [57/100], Train Loss: 0.2603, Train Accuracy: 90.72%, Val Loss: 0.4738, Val Accuracy: 84.75%\n","1\n","Epoch [58/100], Train Loss: 0.2781, Train Accuracy: 89.98%, Val Loss: 0.4665, Val Accuracy: 84.73%\n","1\n","Epoch [59/100], Train Loss: 0.2535, Train Accuracy: 90.72%, Val Loss: 0.4540, Val Accuracy: 85.24%\n","1\n","Epoch [60/100], Train Loss: 0.2581, Train Accuracy: 90.39%, Val Loss: 0.4765, Val Accuracy: 84.86%\n","1\n","Epoch [61/100], Train Loss: 0.2500, Train Accuracy: 90.78%, Val Loss: 0.4569, Val Accuracy: 85.52%\n","1\n","Epoch [62/100], Train Loss: 0.2564, Train Accuracy: 90.51%, Val Loss: 0.4600, Val Accuracy: 84.95%\n","1\n","Epoch [63/100], Train Loss: 0.2483, Train Accuracy: 91.08%, Val Loss: 0.6132, Val Accuracy: 80.53%\n","1\n","Epoch [64/100], Train Loss: 0.2554, Train Accuracy: 90.61%, Val Loss: 0.4769, Val Accuracy: 84.85%\n","1\n","Epoch [65/100], Train Loss: 0.2407, Train Accuracy: 91.23%, Val Loss: 0.4997, Val Accuracy: 84.06%\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-8162de60aca0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-38-cf87b9e85fe4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# 모델 저장\n","torch.save(model.state_dict(), 'bee_lstm_model.pth')"],"metadata":{"id":"xNTFPhEO2qi-"},"execution_count":null,"outputs":[]}]}